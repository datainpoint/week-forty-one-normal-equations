{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb2af0f",
   "metadata": {},
   "source": [
    "# 約維安計畫：正規方程式\n",
    "\n",
    "> 第四十一週\n",
    "\n",
    "![giphy.com](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExYmRoMnN6OG85OHJhY2IyNGZianp1NGptNmZsc3A5dGQ4bTE1ODVxOSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/wvaZFAlOBuuWs/giphy.gif)\n",
    "\n",
    "來源：<https://giphy.com/gifs/cat-television-wvaZFAlOBuuWs>\n",
    "\n",
    "## 什麼是正規方程式\n",
    "\n",
    "在[約維安計畫：機器學習基礎](https://datainpoint.substack.com/p/week-fourty-getting-started-with-machinelearning)一文中我們提到了常見的機器學習任務，其中一項耳熟能詳的「迴歸」其任務描述是要求電腦程式產生一個函數，這個函數能夠將輸入的資料預測某個數值，輸出的資料為連續的形式。我們可以將迴歸視為理解機器學習演算法的第一個里程碑，正規方程式（normal equations）則是協助我們達到這個里程碑的學習演算法，也就是面對迴歸的機器學習任務時的函數生成方法。該函數我們暫且以 h 函數作為命名，意即 hypothesis，h 函數的輸入形式為向量，輸出形式為純量。\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = h(x) = x_0 + w_1x_1 + w_2x_2+...+w_nx_n\n",
    "\\end{equation}\n",
    "\n",
    "h 函數由截距項、權重（或稱係數）以及特徵所組合而成，其中截距項、特徵由資料集提供，權重則由機器學習演算法決定。這邊我們觀察到截距項加上權重的個數恰巧比特徵個數多出一個，如果個數相同，就可以化為向量相乘形式，因此可以為截距項配對一個等於 1 的權重。\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} = h(x) &= w_0x_0 + w_1x_1 + w_2x_2+...+w_nx_n \\; \\text{,where} \\; w_0 = 1 \\\\\n",
    "&=w^\\top x \\; \\text{,where} \\; x \\in \\mathbb{R}^n\n",
    "\\end{align}\n",
    "\n",
    "當輸入 h 函數僅有一個觀測值的特徵，輸入形式為向量、輸出形式為純量；當有多個觀測值的特徵時，輸入形式為矩陣其專有名詞稱為特徵矩陣（feature matrix）、輸出形式為向量。\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = h(X) = Xw \\; \\text{,where} \\; X \\in \\mathbb{R^{m \\times n}}\n",
    "\\end{equation}\n",
    "\n",
    "而正規方程式指的就是，在資料集給定特徵矩陣與目標向量（與模型輸出的預測外型、格式均相同，但是來自於資料集中真實、已實現之數值）的前提下，我們就能夠計算權重向量，進而生成 h 函數。\n",
    "\n",
    "\\begin{equation}\n",
    "w = \\left( X^\\top X \\right)^{-1} X^\\top y \\; \\text{,where} \\; w \\in \\mathbb{R}^n ;\\ y \\in \\mathbb{R}^m\n",
    "\\end{equation}\n",
    "\n",
    "## 權重向量\n",
    "\n",
    "權重向量（weights）是控制模型預測行為的依據，用來決定每個對應的特徵對預測的影響程度。若是第 i 個特徵對應了正權重，則增加此特徵的值會提高預測值，意即對於該特徵與預測為正相關；反之若是第 i 個特徵對應了負權重，則增加此特徵的值會降低預測值，意即對於該特徵與預測為負相關；若是第 i 個特徵的絕對值大，那麼該特徵對於預測的影響力大，反之若是第 i 個特徵的絕對值趨近於零，那麼該特徵對於預測毫無影響力。透過正規方程式我們可以計算出權重向量生成 h 函數，進而獲得輸入特徵對應輸出預測的模型。正規方程式又是如何推導而得？本文已經將「迴歸」的機器學習任務（task, T）定義得相當細膩：在資料給定特徵矩陣與目標向量的情況下生成 h 函數，該 h 函數能夠輸入特徵對應輸出預測。\n",
    "\n",
    "## 效能評估\n",
    "\n",
    "接著是定義效能評估（performance measure, P），當我們透過 h 函數獲得了預測，可以將其與目標向量進行比對，由於預測與目標向量都屬於連續形式，兩者之間的誤差可以由均方誤差（mean square error）決定。\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE} = \\frac{1}{m} \\sum_i \\left( \\hat{y_i} - y_i \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "向量與矩陣形式的計算會比純量運算更加快捷有效率，所以我們將均方誤差改以向量形式表示。\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE} = \\frac{1}{m}  || \\hat{y} - y ||^2 = \\frac{1}{m} || h(X) - y ||^2\n",
    "\\end{equation}\n",
    "\n",
    "為了讓均方誤差最小，可以求解梯度為零的解，梯度（gradient）指的是在向量對函數的偏微分，對應導數（derivative）指的是純量對函數的偏微分。\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_wMSE &= 0 \\\\\n",
    "\\frac{1}{m} \\nabla_w|| Xw - y ||^2 &= 0 \\\\\n",
    "\\nabla_w \\left( Xw - y \\right)^\\top\\left( Xw - y \\right)  &= 0 \\\\\n",
    "\\nabla_w \\left( w^\\top X^\\top Xw - 2w^\\top X^\\top y + y^\\top y \\right) &= 0 \\\\\n",
    "2X^\\top X w - 2X^\\top y &= 0 \\\\\n",
    "X^\\top X w = X^\\top y\\\\\n",
    "w = \\left( X^\\top X \\right)^{-1}X^\\top y\n",
    "\\end{align}\n",
    "\n",
    "至此我們能夠得知正規方程式的求解，源於讓效能評估的均方誤差最小化，進而計算讓權重向量對均方誤差函數的梯度為零的解。\n",
    "\n",
    "## 以 Numpy 實作正規方程式\n",
    "\n",
    "成功推導出正規方程式之後，最後我們寫作一個類別 NormalEquations，以 Python 與 Numpy 模組實作，在給定適當資料集的特徵矩陣與目標向量，能夠生成 h 函數的權重向量。實作過程中我們會用到 Numpy 模組的 np.transpose() 或 ndarray 的 T 屬性來生成轉置矩陣、np.linalg.inv() 來生成反矩陣、np.dot() 或 ndarray 的 dot() 方法來計算向量與矩陣的相乘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786ef1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14883492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalEquations:\n",
    "    def fit(self, X_train, y_train):\n",
    "        m = X_train.shape[0]\n",
    "        intercepts = np.ones(m).reshape(-1, 1)\n",
    "        X = np.concatenate((intercepts, X_train), axis=1)\n",
    "        y = y_train\n",
    "        X_T_X = np.transpose(X).dot(X)\n",
    "        X_T_y = np.transpose(X).dot(y)\n",
    "        X_T_X_inv = np.linalg.inv(X_T_X)\n",
    "        self.w = np.dot(X_T_X_inv, X_T_y)\n",
    "    def predict(self, X_test):\n",
    "        m = X_test.shape[0]\n",
    "        intercepts = np.zeros(m).reshape(-1, 1)\n",
    "        X = np.concatenate((intercepts, X_test), axis=1)\n",
    "        y_pred = np.dot(X, self.w)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68ba55",
   "metadata": {},
   "source": [
    "NormalEquations 類別的使用是以 fit() 方法生成權重向量，並以 predict() 方法將生成預測。我們可以將 NormalEquations 類別應用在 Kaggle 的 House Prices 資料集，藉此來驗證它的可用性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "375e469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/datainpoint/week-forty-one-normal-equations/main/train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/datainpoint/week-forty-one-normal-equations/main/test.csv\")\n",
    "X_train = train[\"OverallQual\"].values.reshape(-1, 1)\n",
    "y_train = train[\"SalePrice\"].values\n",
    "X_test = test[\"OverallQual\"].values.reshape(-1, 1)\n",
    "normal_equations = NormalEquations()\n",
    "normal_equations.fit(X_train, y_train)\n",
    "y_pred = normal_equations.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932dbf80",
   "metadata": {},
   "source": [
    "第四十一週約維安計畫：正規方程式來到尾聲，希望您也和我一樣期待下一篇文章。對於這篇文章有什麼想法呢？喜歡😻、留言🙋‍♂️、訂閱📨或者分享🙌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
